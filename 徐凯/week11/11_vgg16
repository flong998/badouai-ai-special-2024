import tensorflow as tf

# 创建slim对象
slim = tf.contrib.slim  # slim是1x版本的，功能类似2x版本的keras


def vgg_16(inputs,
           num_classes=1000,
           is_training=True,
           dropout_keep_prob=0.5,
           spatial_squeeze=True,
           scope='vgg_16'):
    with tf.variable_scope(scope, 'vgg_16', [inputs]):  # 定义一个名为 'vgg_16' 的作用域，并将输入张量 inputs 传递给该作用域内的操作

        # slim.conv2d 操作应用到 net 上 2 次，每次使用 64 个过滤器和 3x3 的内核大小。所有重复的操作都将在一个名为 conv1 的作用域下进行，方便在tfbd中可视化与调试
        net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')  # .repeat创建重复的神经网络层
        net = slim.max_pool2d(net, [2, 2], scope='pool1')

        net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')
        net = slim.max_pool2d(net, [2, 2], scope='pool2')

        net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')
        net = slim.max_pool2d(net, [2, 2], scope='pool3')

        net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')
        net = slim.max_pool2d(net, [2, 2], scope='pool4')

        net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')
        net = slim.max_pool2d(net, [2, 2], scope='pool5')

        net = slim.conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6')
        net = slim.dropout(net, dropout_keep_prob, is_training=is_training,
                           scope='dropout6')

        net = slim.conv2d(net, 4096, [1, 1], scope='fc7')
        net = slim.dropout(net, dropout_keep_prob, is_training=is_training,
                           scope='dropout7')

        net = slim.conv2d(net, num_classes, [1, 1],
                          activation_fn=None,
                          normalizer_fn=None,
                          scope='fc8')

        # 由于用卷积的方式模拟全连接层，所以输出需要平铺 -> 在卷积层或池化层之后，当需要将四维张量（通常是 [batch_size, height, width, channels]）转换为二维张量
        if spatial_squeeze:
            net = tf.squeeze(net, [1, 2], name='fc8/squeezed')  # 移除张量形状中的第一维与第二维
        return net


# 推理
import matplotlib.image as mpimg


def load_image(path):
    # 读取图片，rgb
    img = mpimg.imread(path)
    # 将图片修剪成中心的正方形
    short_edge = min(img.shape[:2])
    yy = int((img.shape[0] - short_edge) / 2)
    xx = int((img.shape[1] - short_edge) / 2)
    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]
    return crop_img
# 读取图片
img1 = load_image("./test_data/table.jpg")

# 对输入的图片进行resize，使其shape满足(-1,224,224,3)
inputs = tf.placeholder(tf.float32, [None, None, 3])


def resize_image(image, size,
                 method=tf.image.ResizeMethod.BILINEAR,
                 align_corners=False):
    with tf.name_scope('resize_image'):
        image = tf.expand_dims(image, 0)
        image = tf.image.resize_images(image, size,
                                       method, align_corners)
        image = tf.reshape(image, tf.stack([-1,size[0], size[1], 3]))
        return image


resized_img = resize_image(inputs, (224, 224))

# 建立网络结构
prediction = vgg_16(resized_img)

# 载入模型
sess = tf.Session()
# 检查点文件（Checkpoint Files）是训练过程中用于保存模型参数的一种机制
ckpt_filename = './model/vgg_16.ckpt'
# 初始化全局变量
sess.run(tf.global_variables_initializer())
# 训练模型..

# 保存检查点
saver = tf.train.Saver()
# 加载检查点，以继续训练模型
saver.restore(sess, ckpt_filename)

# 最后结果进行softmax预测
# Softmax 函数接收一个包含实数值的向量作为输入，并返回一个新的向量，其中每个元素都在 (0, 1) 区间内，且所有元素之和等于1。这使得输出可以被解释为各个类别的概率
pro = tf.nn.softmax(prediction)
pre = sess.run(pro, feed_dict={inputs: img1})

# 打印预测结果
print("result: ")

import numpy as np


def print_prob(prob, file_path):
    synset = [l.strip() for l in open(file_path).readlines()]
    # 将概率从大到小排列的结果的序号存入pred
    pred = np.argsort(prob)[::-1]
    # 取最大的1个、5个。
    top1 = synset[pred[0]]
    print(("Top1: ", top1, prob[pred[0]]))
    top5 = [(synset[pred[i]], prob[pred[i]]) for i in range(5)]
    print(("Top5: ", top5))
    return top1


print_prob(pre[0], './synset.txt')

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "name_list = os.listdir(r\"data/image/train\")\n",
    "with open(r\"data/dataset.txt\", \"w\") as f:\n",
    "    for name in name_list:\n",
    "        if name.split(\".\")[0] == \"cat\":\n",
    "            f.write(name+\";0\\n\")\n",
    "        elif name.split(\".\")[0] == \"dog\":\n",
    "            f.write(name+\";1\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def img_resize(img_path, size):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255.0\n",
    "    img = cv2.resize(img, size)\n",
    "    return img\n",
    "    \n",
    "def load_image(file_names, batch_size):\n",
    "    n = len(file_names)\n",
    "    i = 0\n",
    "    while True:\n",
    "        images = []\n",
    "        labels = []\n",
    "        for _ in range(batch_size):\n",
    "            if i == 0:\n",
    "                np.random.shuffle(file_names)\n",
    "            file_name = file_names[i]\n",
    "            img_path = os.path.join(r\"data/image/train\", file_name.split(\";\")[0])\n",
    "            x = img_resize(img_path, (224,224))\n",
    "            y = file_name.split(\";\")[1]\n",
    "            images.append(x)\n",
    "            labels.append(y)\n",
    "            i = (i+1)%n\n",
    "        labels = to_categorical(np.array(labels), num_classes=2)\n",
    "        images = np.array(images)\n",
    "        yield (images, labels)  # 这里的生成器只能输出一个张量，有()而不是[]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 54, 54, 48)        17472     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 54, 54, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 26, 26, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 128)       153728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 192)       221376    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 192)       331968    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       221312    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              3277824   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 5,276,034\n",
      "Trainable params: 5,275,682\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\wjh\\AppData\\Local\\Temp\\ipykernel_4120\\2874403001.py:54: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.8317 - accuracy: 0.5411WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 295s 2s/step - loss: 0.8317 - accuracy: 0.5411 - val_loss: 0.6798 - val_accuracy: 0.5625\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.6573 - accuracy: 0.6093WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 268s 2s/step - loss: 0.6573 - accuracy: 0.6093 - val_loss: 0.7031 - val_accuracy: 0.5444\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.6758WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.5984 - accuracy: 0.6758 - val_loss: 0.6273 - val_accuracy: 0.6205\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.7352WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.5226 - accuracy: 0.7352 - val_loss: 0.6678 - val_accuracy: 0.5810\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.4595 - accuracy: 0.7807WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 270s 2s/step - loss: 0.4595 - accuracy: 0.7807 - val_loss: 0.7864 - val_accuracy: 0.5522\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8222WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 270s 2s/step - loss: 0.3891 - accuracy: 0.8222 - val_loss: 0.5398 - val_accuracy: 0.7105\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.8454WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.3448 - accuracy: 0.8454 - val_loss: 0.4450 - val_accuracy: 0.8080\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.3010 - accuracy: 0.8678WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 270s 2s/step - loss: 0.3010 - accuracy: 0.8678 - val_loss: 0.3667 - val_accuracy: 0.8425\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.8900WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 270s 2s/step - loss: 0.2529 - accuracy: 0.8900 - val_loss: 0.5162 - val_accuracy: 0.7401\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.2312 - accuracy: 0.9004WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.2312 - accuracy: 0.9004 - val_loss: 0.5714 - val_accuracy: 0.6998\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.9136WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.2045 - accuracy: 0.9136 - val_loss: 0.3317 - val_accuracy: 0.8602\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.9249WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.1796 - accuracy: 0.9249 - val_loss: 0.3617 - val_accuracy: 0.8602\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.9372WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.1534 - accuracy: 0.9372 - val_loss: 0.5691 - val_accuracy: 0.7726\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9425WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.1387 - accuracy: 0.9425 - val_loss: 0.3383 - val_accuracy: 0.8750\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9510WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.1220 - accuracy: 0.9510 - val_loss: 0.4474 - val_accuracy: 0.8405\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9604WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.0974 - accuracy: 0.9604 - val_loss: 0.4114 - val_accuracy: 0.8569\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9686WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.0833 - accuracy: 0.9686 - val_loss: 0.4619 - val_accuracy: 0.8557\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9710WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.0761 - accuracy: 0.9710 - val_loss: 0.5246 - val_accuracy: 0.8557\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9743WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.0655 - accuracy: 0.9743 - val_loss: 0.6311 - val_accuracy: 0.8721\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9757WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 269s 2s/step - loss: 0.0657 - accuracy: 0.9757 - val_loss: 0.4992 - val_accuracy: 0.8758\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9817WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "175/175 [==============================] - 271s 2s/step - loss: 0.0501 - accuracy: 0.9817 - val_loss: 0.7275 - val_accuracy: 0.8466\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "from model.hw_AlexNet import alexNet\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, \\\n",
    "    ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 处理输入\n",
    "    file_names =[]\n",
    "    with open(\"data/dataset.txt\") as f:\n",
    "        for line in f:\n",
    "            file_names.append(line[:-1])\n",
    "    total_len = len(file_names)\n",
    "    num_val = int(total_len*0.1)\n",
    "    num_train = total_len - num_val\n",
    "    \n",
    "    np.random.seed(38283)\n",
    "    np.random.shuffle(file_names)\n",
    "    np.random.seed(None)\n",
    "    \n",
    "    model = alexNet()\n",
    "    \n",
    "    summary = model.summary()\n",
    "\n",
    "    log_dir = \"logs/\"\n",
    "    \n",
    "    # checkpoint_period1 = ModelCheckpoint(\n",
    "    #                             log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    #                             monitor='acc', \n",
    "    #                             save_weights_only=False, \n",
    "    #                             save_best_only=True, \n",
    "    #                             period=3\n",
    "    #                         )\n",
    "    model_checkPoint = ModelCheckpoint(log_dir + \"ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5\",\n",
    "                                      monitor=\"acc\",\n",
    "                                      save_best_only=True,\n",
    "                                      save_weights_only=False,\n",
    "                                      save_freq=\"epoch\")\n",
    "    reduce_lr = ReduceLROnPlateau(monitor=\"acc\",\n",
    "                                  factor=0.5,\n",
    "                                  patience=3,\n",
    "                                  verbose=1)\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\",\n",
    "                               min_delta=0,\n",
    "                               patience=10,\n",
    "                               verbose=1)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    batch_size=128\n",
    "    model.fit_generator(generator=load_image(file_names[:num_train], batch_size),\n",
    "                        steps_per_epoch=max(1,num_train//batch_size),\n",
    "                        validation_data=load_image(file_names[num_train:], batch_size),\n",
    "                        validation_steps=max(1,num_val//batch_size),\n",
    "                        epochs=50,\n",
    "                        initial_epoch=0,\n",
    "                        callbacks=(model_checkPoint, reduce_lr, early_stop)\n",
    "                        )\n",
    "    model.save_weights(log_dir+\"last1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13:40"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AILesson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
